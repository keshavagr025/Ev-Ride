{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ca559b",
   "metadata": {},
   "source": [
    "## Random Forest (regression part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df828ea8-4756-4017-9cae-12065b7cdadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5000, 22)\n",
      "Columns: ['trip_id', 'city', 'distance_km', 'duration_minutes', 'traffic_level', 'demand_factor', 'battery_health_percent', 'energy_consumption_kwh', 'route_difficulty', 'vehicle_type', 'time_of_day', 'day_of_week', 'weather_condition', 'temperature_celsius', 'humidity_percent', 'driver_rating', 'surge_multiplier', 'historical_pricing_factor', 'is_holiday', 'charging_stations_nearby', 'user_type', 'fare_amount_inr']\n",
      "    trip_id       city  distance_km  duration_minutes  traffic_level  \\\n",
      "0  EV000001       Pune        15.23              40.5             60   \n",
      "1  EV000002     Mumbai        23.72              70.5             60   \n",
      "2  EV000003      Delhi        30.65             145.8             81   \n",
      "3  EV000004  Bangalore        51.44             109.9             88   \n",
      "4  EV000005  Bangalore        16.72              67.7             60   \n",
      "\n",
      "   demand_factor  battery_health_percent  energy_consumption_kwh  \\\n",
      "0        2.58570                      79                    4.84   \n",
      "1        1.24488                      82                    5.59   \n",
      "2        1.98000                      96                    8.57   \n",
      "3        0.97200                      95                    7.44   \n",
      "4        2.09300                      90                    6.54   \n",
      "\n",
      "   route_difficulty vehicle_type  ... weather_condition temperature_celsius  \\\n",
      "0                 4        Sedan  ...             Foggy                  17   \n",
      "1                 4          SUV  ...             Storm                  26   \n",
      "2                 6      Compact  ...               Hot                  25   \n",
      "3                 7        Sedan  ...             Foggy                  15   \n",
      "4                 7      Compact  ...             Foggy                  16   \n",
      "\n",
      "  humidity_percent  driver_rating  surge_multiplier  \\\n",
      "0               45            4.5              2.47   \n",
      "1               60            3.6              2.00   \n",
      "2               57            3.6              1.00   \n",
      "3               61            3.7              1.00   \n",
      "4               55            4.1              1.71   \n",
      "\n",
      "   historical_pricing_factor  is_holiday  charging_stations_nearby  user_type  \\\n",
      "0                       0.94           0                         4    Premium   \n",
      "1                       0.93           0                         7    Premium   \n",
      "2                       0.98           1                         9    Regular   \n",
      "3                       1.04           0                         4    Premium   \n",
      "4                       0.97           0                         7    Premium   \n",
      "\n",
      "   fare_amount_inr  \n",
      "0          1130.74  \n",
      "1          1142.17  \n",
      "2           929.03  \n",
      "3          1043.40  \n",
      "4           825.76  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "                            count unique       top  freq         mean  \\\n",
      "trip_id                      5000   5000  EV000001     1          NaN   \n",
      "city                         5000      5      Pune  1032          NaN   \n",
      "distance_km                5000.0    NaN       NaN   NaN    26.695284   \n",
      "duration_minutes           5000.0    NaN       NaN   NaN     93.74854   \n",
      "traffic_level              5000.0    NaN       NaN   NaN       56.975   \n",
      "demand_factor              5000.0    NaN       NaN   NaN     2.213393   \n",
      "battery_health_percent     5000.0    NaN       NaN   NaN       84.974   \n",
      "energy_consumption_kwh     5000.0    NaN       NaN   NaN     5.947768   \n",
      "route_difficulty           5000.0    NaN       NaN   NaN       5.5014   \n",
      "vehicle_type                 5000      4     Sedan  1285          NaN   \n",
      "time_of_day                  5000      5     Night  1042          NaN   \n",
      "day_of_week                  5000      7    Sunday   757          NaN   \n",
      "weather_condition            5000      5     Foggy  1027          NaN   \n",
      "temperature_celsius        5000.0    NaN       NaN   NaN      26.9344   \n",
      "humidity_percent           5000.0    NaN       NaN   NaN      64.6434   \n",
      "driver_rating              5000.0    NaN       NaN   NaN      4.26174   \n",
      "surge_multiplier           5000.0    NaN       NaN   NaN     1.618622   \n",
      "historical_pricing_factor  5000.0    NaN       NaN   NaN     1.001262   \n",
      "is_holiday                 5000.0    NaN       NaN   NaN       0.1012   \n",
      "charging_stations_nearby   5000.0    NaN       NaN   NaN       5.4778   \n",
      "user_type                    5000      2   Premium  2507          NaN   \n",
      "fare_amount_inr            5000.0    NaN       NaN   NaN  1937.595396   \n",
      "\n",
      "                                   std    min      25%      50%        75%  \\\n",
      "trip_id                            NaN    NaN      NaN      NaN        NaN   \n",
      "city                               NaN    NaN      NaN      NaN        NaN   \n",
      "distance_km                  14.471448   2.01     14.3   26.475     39.305   \n",
      "duration_minutes             57.189285    4.7   46.375     87.7      132.2   \n",
      "traffic_level                25.195415    0.0     42.0     60.0       75.0   \n",
      "demand_factor                 1.064179   0.45  1.34325  2.09682   2.890875   \n",
      "battery_health_percent        9.022505   70.0     77.0     85.0       93.0   \n",
      "energy_consumption_kwh        1.308385    3.2     4.98     5.88       6.81   \n",
      "route_difficulty              2.906697    1.0      3.0      5.0        8.0   \n",
      "vehicle_type                       NaN    NaN      NaN      NaN        NaN   \n",
      "time_of_day                        NaN    NaN      NaN      NaN        NaN   \n",
      "day_of_week                        NaN    NaN      NaN      NaN        NaN   \n",
      "weather_condition                  NaN    NaN      NaN      NaN        NaN   \n",
      "temperature_celsius           7.204448   15.0     21.0     27.0       33.0   \n",
      "humidity_percent             20.137233   30.0     47.0     65.0       82.0   \n",
      "driver_rating                 0.432791    3.5      3.9      4.3        4.6   \n",
      "surge_multiplier              0.539685    1.0      1.0     1.75       2.03   \n",
      "historical_pricing_factor     0.058238    0.9     0.95      1.0       1.05   \n",
      "is_holiday                    0.301624    0.0      0.0      0.0        0.0   \n",
      "charging_stations_nearby       2.85502    1.0      3.0      5.0        8.0   \n",
      "user_type                          NaN    NaN      NaN      NaN        NaN   \n",
      "fare_amount_inr            2205.657821  16.47  449.805  1080.66  2694.0825   \n",
      "\n",
      "                                max  \n",
      "trip_id                         NaN  \n",
      "city                            NaN  \n",
      "distance_km                   51.99  \n",
      "duration_minutes              255.6  \n",
      "traffic_level                  99.0  \n",
      "demand_factor                5.4418  \n",
      "battery_health_percent        100.0  \n",
      "energy_consumption_kwh        10.34  \n",
      "route_difficulty               10.0  \n",
      "vehicle_type                    NaN  \n",
      "time_of_day                     NaN  \n",
      "day_of_week                     NaN  \n",
      "weather_condition               NaN  \n",
      "temperature_celsius            39.0  \n",
      "humidity_percent               99.0  \n",
      "driver_rating                   5.0  \n",
      "surge_multiplier                2.5  \n",
      "historical_pricing_factor       1.1  \n",
      "is_holiday                      1.0  \n",
      "charging_stations_nearby       10.0  \n",
      "user_type                       NaN  \n",
      "fare_amount_inr            19317.83  \n",
      "Missing values per column:\n",
      " trip_id                      0\n",
      "city                         0\n",
      "user_type                    0\n",
      "charging_stations_nearby     0\n",
      "is_holiday                   0\n",
      "historical_pricing_factor    0\n",
      "surge_multiplier             0\n",
      "driver_rating                0\n",
      "humidity_percent             0\n",
      "temperature_celsius          0\n",
      "weather_condition            0\n",
      "day_of_week                  0\n",
      "time_of_day                  0\n",
      "vehicle_type                 0\n",
      "route_difficulty             0\n",
      "energy_consumption_kwh       0\n",
      "battery_health_percent       0\n",
      "demand_factor                0\n",
      "traffic_level                0\n",
      "duration_minutes             0\n",
      "distance_km                  0\n",
      "fare_amount_inr              0\n",
      "dtype: int64\n",
      "After trimming target outliers shape: (4900, 22)\n",
      "Feature count: 19\n",
      "Numeric cols: 13 Categorical cols: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2868\\2329203141.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dt = pd.to_datetime(df[c], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# full_rf_pipeline.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, joblib\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# ------------- Helper functions -------------\n",
    "def haversine_series(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, (lat1, lon1, lat2, lon2))\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def print_metrics(y_true, y_pred, label=\"Test\"):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    accuracy = 1 - (mae / (y_true.mean() if y_true.mean() != 0 else 1))\n",
    "    print(f\"\\n{label} Metrics:\")\n",
    "    print(f\"R2:   {r2:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"Accuracy (1 - MAE/mean(y)): {accuracy:.4f}\")\n",
    "    return {\"r2\": r2, \"mae\": mae, \"rmse\": rmse, \"acc\": accuracy}\n",
    "\n",
    "# ------------- Load data -------------\n",
    "df = pd.read_csv(\"newData.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ------------- Target selection (adjust if needed) -------------\n",
    "# If your target column is not fare_amount_inr, set it here:\n",
    "target = \"fare_amount_inr\"\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"Target column {target} not found. Change `target` variable in the script.\")\n",
    "\n",
    "# ------------- Basic EDA -------------\n",
    "print(df.head())\n",
    "print(df.describe(include='all').T)\n",
    "print(\"Missing values per column:\\n\", df.isna().sum().sort_values(ascending=False).head(30))\n",
    "\n",
    "# ------------- Optional: remove extreme outliers (target) -------------\n",
    "# If the fare distribution has wild outliers, you may wish to clip or remove extremes.\n",
    "# Example: keep rows with target within 1st-99th percentile\n",
    "low, high = df[target].quantile([0.01, 0.99])\n",
    "df = df[(df[target] >= low) & (df[target] <= high)]\n",
    "print(\"After trimming target outliers shape:\", df.shape)\n",
    "\n",
    "# ------------- Feature engineering (customize per your columns) -------------\n",
    "# If you have pickup/drop lat/lon columns, create distance. Modify names below to match your dataset.\n",
    "lat_candidates = [c for c in df.columns if 'lat' in c.lower()]\n",
    "lon_candidates = [c for c in df.columns if 'lon' in c.lower() or 'lng' in c.lower()]\n",
    "\n",
    "if len(lat_candidates) >= 2 and len(lon_candidates) >= 2:\n",
    "    p_lat, d_lat = lat_candidates[0], lat_candidates[1]\n",
    "    p_lon, d_lon = lon_candidates[0], lon_candidates[1]\n",
    "    try:\n",
    "        df[\"distance_km\"] = haversine_series(df[p_lat], df[p_lon], df[d_lat], df[d_lon])\n",
    "        print(\"Created distance_km from\", p_lat, p_lon, d_lat, d_lon)\n",
    "    except Exception as e:\n",
    "        print(\"Could not create distance_km:\", e)\n",
    "\n",
    "# If there are datetime columns, extract hour/day/month/weekend\n",
    "for c in df.columns:\n",
    "    if 'time' in c.lower() or 'date' in c.lower() or 'datetime' in c.lower():\n",
    "        try:\n",
    "            dt = pd.to_datetime(df[c], errors='coerce')\n",
    "            if dt.notna().sum() > 0.5*len(df):\n",
    "                df[c + \"_dt\"] = dt\n",
    "                df[c + \"_hour\"] = dt.dt.hour\n",
    "                df[c + \"_weekday\"] = dt.dt.weekday\n",
    "                df[c + \"_month\"] = dt.dt.month\n",
    "                print(\"Extracted datetime features from\", c)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Example domain-specific features for ride-sharing:\n",
    "if 'duration_minutes' in df.columns and 'distance_km' in df.columns:\n",
    "    df['speed_kmph'] = df['distance_km'] / (df['duration_minutes'] / 60.0 + 1e-6)\n",
    "    df['speed_kmph'] = df['speed_kmph'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# ------------- Prepare features and labels -------------\n",
    "id_like = [c for c in df.columns if 'id' in c.lower() or 'trip' in c.lower()]\n",
    "X = df.drop(columns=[target] + id_like, errors='ignore')\n",
    "y = df[target].copy()\n",
    "print(\"Feature count:\", X.shape[1])\n",
    "\n",
    "# ------------- Categorical handling strategy -------------\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(\"Numeric cols:\", len(numeric_cols), \"Categorical cols:\", len(cat_cols))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19019a30-4529-4f2c-9b0d-9c8811c8571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "27 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.87570042 0.88829663 0.88207096 0.86835921        nan 0.86945073\n",
      " 0.85666884 0.86980306 0.83430437 0.88635147 0.82399257        nan\n",
      " 0.88673567        nan        nan 0.88027679 0.81772576 0.88086458\n",
      " 0.84133819 0.86385195        nan        nan 0.82975875 0.85802387\n",
      " 0.86776968        nan        nan 0.87575349        nan 0.84388315]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      " BEST HYPERPARAMETERS FOUND \n",
      "============================\n",
      "{'model__n_estimators': 200, 'model__min_samples_split': 2, 'model__min_samples_leaf': 1, 'model__max_features': 0.3, 'model__max_depth': 20, 'model__bootstrap': False}\n",
      "\n",
      "============================\n",
      " FINAL MODEL PERFORMANCE \n",
      "============================\n",
      "R¬≤ Score: 0.9165\n",
      "MAE: 328.7700\n",
      "RMSE: 531.9335\n",
      "Custom Accuracy: 0.8153\n",
      "\n",
      "Model saved to: /mnt/data/best_rf_ev_fare_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# üöÄ EV Price Prediction RF Model\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1) Load Dataset\n",
    "# ---------------------------------------------\n",
    "df = pd.read_csv(\"newData.csv\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2) Target Column\n",
    "# ---------------------------------------------\n",
    "target = \"fare_amount_inr\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3) Remove ID Column (not useful for ML)\n",
    "# ---------------------------------------------\n",
    "df = df.drop(columns=[\"trip_id\"])\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4) Remove Outlier Fares (1% high + low)\n",
    "# ---------------------------------------------\n",
    "low, high = df[target].quantile([0.01, 0.99])\n",
    "df = df[(df[target] >= low) & (df[target] <= high)]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5) Split Features + Labels\n",
    "# ---------------------------------------------\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6) Identify Column Types\n",
    "# ---------------------------------------------\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Low-cardinality ‚Üí OneHot\n",
    "ohe_cols = [c for c in cat_cols if X[c].nunique() <= 10]\n",
    "\n",
    "# High-cardinality ‚Üí LabelEncode\n",
    "label_cols = [c for c in cat_cols if X[c].nunique() > 10]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 7) Encode high-cardinality categorical columns\n",
    "# ---------------------------------------------\n",
    "for c in label_cols:\n",
    "    X[c] = LabelEncoder().fit_transform(X[c].astype(str))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 8) Convert OHE columns to string (fix sklearn error)\n",
    "# ---------------------------------------------\n",
    "for c in ohe_cols:\n",
    "    X[c] = X[c].astype(str)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 9) Build Preprocessing Transformer\n",
    "# ---------------------------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "# NOTE: sparse_output=False is required for new sklearn versions\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), ohe_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 10) Random Forest Model\n",
    "# ---------------------------------------------\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "pipe = Pipeline(steps=[(\"pre\", preprocessor), (\"model\", rf)])\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 11) Hyperparameter Search Space\n",
    "# ---------------------------------------------\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [200, 400, 600, 800],\n",
    "    \"model__max_depth\": [10, 15, 20, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],\n",
    "    \"model__max_features\": [\"auto\", \"sqrt\", 0.3],\n",
    "    \"model__bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 12) Train / Test Split\n",
    "# ---------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 13) Randomized Search CV\n",
    "# ---------------------------------------------\n",
    "rs = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n============================\")\n",
    "print(\" BEST HYPERPARAMETERS FOUND \")\n",
    "print(\"============================\")\n",
    "print(rs.best_params_)\n",
    "\n",
    "best_model = rs.best_estimator_\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 14) Predictions\n",
    "# ---------------------------------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 15) Metrics\n",
    "# ---------------------------------------------\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "accuracy = 1 - (mae / y_test.mean())\n",
    "\n",
    "print(\"\\n============================\")\n",
    "print(\" FINAL MODEL PERFORMANCE \")\n",
    "print(\"============================\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Custom Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 16) Save Best Model\n",
    "# ---------------------------------------------\n",
    "joblib.dump(best_model, \"best_rf_ev_fare_model.pkl\")\n",
    "\n",
    "\n",
    "print(\"\\nModel saved to: /mnt/data/best_rf_ev_fare_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28a71dc9-762c-4e2b-b556-870f208a1313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Top Features:\n",
      " ['demand_factor', 'distance_km', 'vehicle_type_Premium', 'surge_multiplier', 'driver_rating', 'battery_health_percent', 'vehicle_type_Compact', 'energy_consumption_kwh', 'traffic_level', 'duration_minutes', 'vehicle_type_SUV', 'historical_pricing_factor', 'humidity_percent', 'route_difficulty', 'weather_condition_Storm']\n",
      "\n",
      "==============================\n",
      "      KNN FARE PREDICTION     \n",
      "==============================\n",
      "R¬≤ Score: 0.2061\n",
      "MAE: 1193.4688\n",
      "RMSE: 1640.4826\n",
      "Custom Accuracy: 0.3297\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# KNN REGRESSOR (WITH PREPROCESSING)\n",
    "# =====================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# --------------------------\n",
    "# Load clean data\n",
    "# --------------------------\n",
    "df = pd.read_csv(\"newData.csv\")\n",
    "df = df.drop(columns=[\"trip_id\"])\n",
    "target = \"fare_amount_inr\"\n",
    "\n",
    "# Remove outlier fares\n",
    "low, high = df[target].quantile([0.01, 0.99])\n",
    "df = df[(df[target] >= low) & (df[target] <= high)]\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# --------------------------\n",
    "# Identify columns\n",
    "# --------------------------\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "ohe_cols = [c for c in cat_cols if X[c].nunique() <= 10]\n",
    "label_cols = [c for c in cat_cols if X[c].nunique() > 10]\n",
    "\n",
    "# Label Encode high card\n",
    "for c in label_cols:\n",
    "    X[c] = LabelEncoder().fit_transform(X[c].astype(str))\n",
    "\n",
    "# Convert OHE columns to str\n",
    "for c in ohe_cols:\n",
    "    X[c] = X[c].astype(str)\n",
    "\n",
    "# --------------------------\n",
    "# Preprocessor\n",
    "# --------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), ohe_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# STEP 1: Feature Selection using Random Forest\n",
    "# --------------------------\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "pipe_rf = Pipeline(steps=[(\"pre\", preprocessor), (\"rf\", rf)])\n",
    "\n",
    "# Fit RF for feature importance\n",
    "pipe_rf.fit(X, y)\n",
    "importances = pipe_rf.named_steps[\"rf\"].feature_importances_\n",
    "\n",
    "# Get transformed feature names\n",
    "ohe_feature_names = []\n",
    "if ohe_cols:\n",
    "    ohe_feature_names = pipe_rf.named_steps[\"pre\"].named_transformers_[\"ohe\"].get_feature_names_out(ohe_cols)\n",
    "\n",
    "all_features = numeric_cols + list(ohe_feature_names) + label_cols\n",
    "\n",
    "feat_df = pd.DataFrame({\"feature\": all_features, \"importance\": importances})\n",
    "feat_df = feat_df.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "top_features = feat_df.head(15)[\"feature\"].tolist()\n",
    "print(\"\\nSelected Top Features:\\n\", top_features)\n",
    "\n",
    "# --------------------------\n",
    "# STEP 2: Transform X AND select features\n",
    "# --------------------------\n",
    "X_transformed = pipe_rf.named_steps[\"pre\"].transform(X)\n",
    "X_transformed = pd.DataFrame(X_transformed, columns=all_features)\n",
    "\n",
    "X_selected = X_transformed[top_features]\n",
    "\n",
    "# --------------------------\n",
    "# Train/Test split\n",
    "# --------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# STEP 3: TRAIN KNN\n",
    "# --------------------------\n",
    "knn = KNeighborsRegressor(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# --------------------------\n",
    "# STEP 4: Metrics\n",
    "# --------------------------\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "custom_accuracy = 1 - (mae / y_test.mean())\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"      KNN FARE PREDICTION     \")\n",
    "print(\"==============================\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Custom Accuracy: {custom_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0c9d56e-7a6c-4978-bfb3-57ae69cda245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "       SVR PERFORMANCE         \n",
      "==============================\n",
      "R¬≤ Score: 0.8352\n",
      "MAE: 368.29\n",
      "RMSE: 747.37\n",
      "Custom Accuracy: 0.7931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"newData.csv\")\n",
    "df = df.drop(columns=[\"trip_id\"])\n",
    "\n",
    "target = \"fare_amount_inr\"\n",
    "\n",
    "# Remove outlier fares\n",
    "low, high = df[target].quantile([0.01, 0.99])\n",
    "df = df[(df[target] >= low) & (df[target] <= high)]\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Column types\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "ohe_cols = [c for c in cat_cols if X[c].nunique() <= 10]\n",
    "label_cols = [c for c in cat_cols if X[c].nunique() > 10]\n",
    "\n",
    "# Label encode high-card categorical\n",
    "for c in label_cols:\n",
    "    X[c] = LabelEncoder().fit_transform(X[c].astype(str))\n",
    "\n",
    "# Convert OHE cols to string\n",
    "for c in ohe_cols:\n",
    "    X[c] = X[c].astype(str)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())     # ‚≠ê IMPORTANT FOR SVM\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), ohe_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# SVR model\n",
    "svr = SVR(kernel=\"rbf\", C=100, gamma=\"scale\")\n",
    "\n",
    "model = Pipeline(steps=[(\"pre\", preprocessor), (\"svr\", svr)])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "custom_accuracy = 1 - (mae / y_test.mean())\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"       SVR PERFORMANCE         \")\n",
    "print(\"==============================\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"Custom Accuracy: {custom_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630546f8-cf38-45c2-86e1-843b934a5fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
